{"title":"Masters Project Introductory Post","markdown":{"yaml":{"title":"Masters Project Introductory Post","author":"Adnan Jinnah","date":"2022-09-25","toc":true,"number-sections":true,"jupyter":"python3","categories":["Masters"]},"headingText":"Intro","containsRefs":false,"markdown":"\n\nThis is the start of a series of posts about my Masters project with the Physics Department at Durham University.\n\nTo being with, here is the official project description as presented by the department:\n\n# Title: Data science for biodiversity loss\n\nSupervisor: Prof Charles Adams.\nSecond Supervisor: Dr Robert Potvliege.\nCategory: General.\nType: Computation/Data Analysis/Experiment.\n\nBiodiversity loss due to human action is increasingly creating an existential threat to all live on Earth. In order to take appropriate action we need better data. However biodiversity data is both more diverse and more difficult to accumulate than say climate data. In this project, we shall look at data analysis on bird song. Although, under ideal conditions it is possible to identify different species [1-3]. In a noisy environment, which is more typical, this becomes more challenging. One approach that we shall pursue is to construct time frequency pattern and then use pattern recognition technique to identify particular events [4].\n\n[1]  [scikit‐maad An open‐source and modular toolbox for quantitative soundscape analysis in Python, Ulloa et al, Meth. in Ecology and Evolution, 12, 2334 2021](https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/2041-210X.13711)\n\n[2]  [Multifractal analysis of birdsong and its correlation structure, R Bishal, GB Mindlin, and N Gupte Phys. Rev. E 105, 014118 2022](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.105.014118)\n\n[3]  [Large-scale analysis of frequency modulation in birdsong data bases, D Stowell, MD Plumbley, Methods Ecol Evol, 5: 901 (2014)](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12223)\n\n[4]  [New aspects in birdsong recognition utilizing the gabor transform, S HEUER , P TAFO, H HOLZMANN, S DAHLKE, Proc. of the 23rd Int. Congress on Acousitics, Aachen, September 9-13, 2019.](https://www.mathematik.uni-marburg.de/~heuersv/paper/birdsong_recognition_utilizing_gabor_transform.pdf)\n\n# Aim\nIn essence, the (first) aim of this project is to pick apart bird song from a noisy sound recording and identify birds from it. \n\nIn the future other aims may emerge, such as trying to understand the meaning behind birdsong rather than classify their singers. Perhaps even trying to generate birdsong may be an interesting idea to yield some insights. It would be fascinating seeing if/how birds would respond to generated birdsong. \n\n# Approaches\nThe four above referenced papers are probably the best place to start when looking for initial approaches. While I am comfortable with both Physics and Programming, my preference in comfortability and in interest does lean towards the latter, especially when Machine Learning is involved. Having said that, the first, third and fourth reference all are ML based to a degree. \n\nI don't yet have the prerequisite knowledge to understand at a glance the abstracts of the second and third references. \n\nThe first however is an open-source Python module called scikit-maad, which is instantly recognisable by my familiarity with other popular scikit modules. Furthermore, I feel warmly welcomed by the described online documentation and practical examples around it. Lastly, the module highlights its ability to easily integrate Machine Learning Python packages. \n\nThe fourth reference details that current approaches convert audio recordings into spectrograms using the Gabor transform, then enter them as images to a CNN for classification. This is a really intuitive ML approach, and one I might try and implement. The paper then details that most approaches focus on finding the best CNN hyperparameters for accuracy, so in contrast the authors attempt to evaluate the parameters for the Gabor transform itself.\n\nAll in all, I think my first priority is to investigate and implement the first and fourth references. It's not ideal not being able to easily understand the other papers, but my reasoning is that having gone through the more understandable references first would yield prerequisite knowledge to go back and understand the others.\n\nCoincidentally, I was talking briefly with my older brother about the project and he commented that the problem is awfully similar to other audio separation problems. Separating out bird song from a noisy forest environment and then identifying them, is similar to separating out instrument sounds from a regular song and identifying them. We both actually have a mutual friend who did his Masters project in the latter. Spotify also appears to have its own development going on for this problem. Looking through how similar these two problems are might prove very useful.\n\nI will meet with my supervisors next week and discuss our next steps in more detail. The fast.ai part 2 course is releasing soon and I would like to progress through it both for the sake of the project and my own interests.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"number-sections":true,"output-file":"2022-09-25-MP1.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","theme":"cosmo","title-block-banner":true,"title":"Masters Project Introductory Post","author":"Adnan Jinnah","date":"2022-09-25","jupyter":"python3","categories":["Masters"]},"extensions":{"book":{"multiFile":true}}}}}