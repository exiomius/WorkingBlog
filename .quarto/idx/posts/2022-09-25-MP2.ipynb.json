{"title":"Masters Project 04/10/2022","markdown":{"yaml":{"title":"Masters Project 04/10/2022","author":"Adnan Jinnah","date":"2022-10-04","toc":true,"number-sections":true,"jupyter":"python3","categories":["Masters"]},"headingText":"Intro","containsRefs":false,"markdown":"\n\nThe second post from a series of posts about my Masters project with the Physics Department at Durham University.\n\n# Meeting:\n## During the meeting we discussed:\n- What I had been learning during the summer, namely the first fast.ai course, the state of exponential growth of machine learning, my website, etc. We are all happy with the progress I have made so far. I will estimate that I spent around 40 hours working this summer, ahead of the 30 hours the department set.\n- For example, I showed how I can upload machine learning models to HuggingFaceSpaces, which lets me send a link easily to Stuart, Robert, the biology dept etc and let them test and play with what I'm doing. This will be very useful as I physically will not need to take my computer over to get feedback on models.\n- How the project will be examined: by extended report (like a dissertation), a seminar, a supervisors mark (on your effort and from a viva), and also a provisional formative 10 page report. An external supervisor will be picked at random from 4 academics Stuart and Robert pick to read your report.\n- Stuart said to take the formative report seriously, because feedback on your writing style etc is really important. Your supervisors can't give feedback on your real report later on due to department rules.\n- We will meet with Phil and Steve, from the biology department, next week, meeting at the TLC at 10:55.\n- Stuart has two audio recording devices that use SD cards to record. He said that he will order SD cards. I could use these to collect sound data if necessary. There is a large amount of data already collected, both by the biology department and available online, but if I wanted data collected in a specific way, then I could do it myself. For example, as we have two devices, I could set both of them up to gather the same audio, and use that to analyse out noise. What I could do, is use the same microphones the biology department did, and use them to remove noise from their whole dataset.\n- On a ambitious note, the biology department has been using community volunteers to look through photos and label animals in them. In a similar way, if this project is really successful, we could get a grant to lend out a specific recording setup to them and get a lot of specific data. \n- Robert explained some possible project aims relating to biodiversity. For example, if we could classify birds by audio, we could look for birds that shouldn't be in the UK or in specific areas. Birds that are migrating in the wrong direction, due to climate change or other environmental issues. This could tell us about biodiversity. If we had data of audio collected over months or years, then about how biodiversity is changing over time. I commented that if the biology department also recorded the GPS location of their recording device, it could be possible to map out how the number of specific birds changes in various areas.\n- I asked Stuart whether any of his other supervision students are working on a similar problem to me. While he has many students, we are all doing varied projects which is interesting but hinders collaboration. For now, there should be a PhD student working with the biology team with I could work with.\n- I explained that I want my diss to be written in a way it can be understood by anyone with no prerequisite knowledge. This stems from me expressing that the fundamental mechanisms in which machine learning works is actually very simple, it's high school level maths and can be explained in one or two pages. This approach is good because it will make examination and marking easier. \n- I explained that for frequent progress updates, I want to continue writing blogs on this website and link it to the teams channel. Right now one blog a week after the week's meeting is probably a good pace.\n- We agreed on my plan to spend half my time working directly on the problem, and the other half going through the second fast.ai course starting Tuesday next week.\n\n# I also attended the intro physics project talk this week:\n- Level 4 contributes to 44.4% of your final year mark.\n- My other modules, atomslasersqubits and planets&cosmology, have one self assessed problem a week.\n- Planets&Cos has 80% exam, and 20% essay. Choose a topic and write 1500-words for deadline 2pm Friday 10th Feb, but from disabilities I may be able to get an extension if needed.\n- Technical support at physics.level4lab@durham.ac.uk to help with small scale jobs, advice, equipment ordering. Could be useful to setup recording devices for me.\n- There are weekly Python computing drop in sessions at Ph216 at 12-1pm on Mondays and Thursday with PhD students to help etc. Also there's an online support website. \n- Assessment: In order. Seminar 5% between 27th Feb-3rd March. Oral exam 25% between 24th April-2nd May. 40% report, 30 pages, 2pm Weds 19th April deadline. 30% supervisors' mark from supervisors' thoughts about my effort and a viva.\n- Majority of the diss writing happens over Easter. The deadline is 2pm Weds 19th April, a week before 3rd term.\n- Upload updates to the project on teams to act as a record. It helps with the supervisors' mark. It helps with external examiners to act as evidence between interaction between student and supervisors. Great for diss writing.\n- Short 10 page interim report for Christmas assessed by main supervisor. \n- Advice to write reports in LaTeX, although I think I will write mine in Jupyter notebooks for easy code integration like how the fast.ai textbook is written.\n- Oral exam/Viva, 25 minutes, with an examiner, moderator, supervisors. No formative practice for this. \n- Formative 10 minute seminar with supervisors after Christmas. \n- Can borrow equipment from labs if given permission. Might need to do a risk assessment.\n\n# Next Steps:\n\n## This week I want to:\n- Finish fast.ai part 1. Namely the questions and blog posts for the last 2 lessons.\n- Go and investigate some of the project's proposal's references starting with scikit-maad and a CNN classifier. \n- Ask for a reimbursement for fast.ai part 2\n\n# Long term plan:\n\n- Spend half my time going at the problem directly. The proposal references. I found that fast.ai have an audio library, fastaudio at https://github.com/fastaudio/fastaudio, and online I found several blog posts about people using it to classify birds. https://www.ecosia.org/search?q=fast%20ai%20fastaudio%20bird%20classification&addon=opensearch. Also it would be good to learn some domain specific knowledge, I.E, knowledge about birds and bird songs, specific knowledge that is helpful to inform ML models.\n- Spend the other half of my time learning more machine learning knowledge, namely, working through the fast.ai part 2 course starting next week. My reasoning is as follows: the second course covers more advanced topics likely highly important for my Masters. For example, how to implement the most recent ML papers into your work, which requires higher knowledge about how to edit code architecture. And further forward, if I want to add explainable AI modules into my work, this knowledge may prove useful. Lastly, there's likely many useful topics covered that I don't get know of.\n- As a side, this style of plan is inspired by Jeremy Howard, the creator of fast.ai. He said that thinks spending half your time working and half your time learning is a great approach for computer science. The combination of real practice while also learning is good.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"number-sections":true,"output-file":"2022-09-25-MP2.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","theme":"cosmo","title-block-banner":true,"title":"Masters Project 04/10/2022","author":"Adnan Jinnah","date":"2022-10-04","jupyter":"python3","categories":["Masters"]},"extensions":{"book":{"multiFile":true}}}}}