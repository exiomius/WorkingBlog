{
 "cells": [
  {
   "cell_type": "raw",
   "id": "938848c6",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"AIS 1: Artificial General Intelligence\"\n",
    "author: \"Adnan Jinnah\"\n",
    "date: \"2022-10-22\"\n",
    "toc: true\n",
    "number-sections: true\n",
    "jupyter: python3\n",
    "categories: [AIS]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab697dd",
   "metadata": {},
   "source": [
    "# Intro\n",
    "This is the first post in a series about AI safety (AIS). I am apart of the effective altruism AI discussion group at Durham, and these posts will be detailing my experience and notes about the topics we discuss.\n",
    "(This post is still in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24956b9",
   "metadata": {},
   "source": [
    "# Course Details\n",
    "We will be following the AGISF curriculum at https://www.agisafetyfundamentals.com/ai-alignment-curriculum. This includes 8 weeks of readings and discussions, followed by a final project. The Core readings and homework can be found here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7b0fc",
   "metadata": {},
   "source": [
    "# Homework\n",
    "For week 1, the homework is to read all 5 core readings in Week 1 the AGISF Curriculum and answer down answers to some questions.\n",
    "This week, it's Exercise 1, and Discussion Prompts 2,3 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b32e4f9",
   "metadata": {},
   "source": [
    "## Core Reading 1: Four Background Claims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174261e",
   "metadata": {},
   "source": [
    "## Core Reading 2: AGI safety from first principles (Ngo, 2020) \n",
    "(from section 1 to end of 2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39cd12",
   "metadata": {},
   "source": [
    "## Core Reading 3: More is different for AI (Steinhardt, 2022) \n",
    "(only introduction, second post, third post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bab52",
   "metadata": {},
   "source": [
    "## Core Reading 4: “Most important century” series summary (Karnofsky, 2021a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd0679",
   "metadata": {},
   "source": [
    "## Core Reading 5: Forecasting transformative AI: the “biological anchors” method in a nutshell (Karnofsky, 2021b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000e2b",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "As discussed in Ngo (2020), Legg and Hutter define intelligence as “an agent’s ability to achieve goals in a wide range of environments”: a definition of intelligence in terms of the outcomes it leads to. An alternative approach is to define intelligence in terms of the cognitive skills (memory, planning, etc) which intelligent agents used to achieve their desired outcomes. What are the key cognitive skills which should feature in such a definition of intelligence?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24acb1",
   "metadata": {},
   "source": [
    "## Discussion Prompts 2\n",
    "One intuition for how to think about very smart AIs: imagine speeding up human intellectual development by a factor of X. If an AI could do the same quality of research as a top scientist, but 10 or 100 times faster, and with the ability to make thousands of copies, how would you use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f73238",
   "metadata": {},
   "source": [
    "## Discussion Prompts 3\n",
    "How frequently do humans build technologies where some of the details of why they work aren’t understood by anyone? What, if anything, makes AI different from other domains? Would it be very surprising if we built AGI without understanding very much about how its thinking process works?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b452f94",
   "metadata": {},
   "source": [
    "## Discussion Prompts 5\n",
    "What are the most plausible ways for the hypothesis “we will eventually build AGIs which have transformative impacts on the world” to be false? How likely are they?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
